model:
  in_channel: 1
  K: 6  # 2, 3, 4a, 4b, 4c, 5
  width: 16

  # for (512, 512) image, unet level + ypath level <= 8
  # 3, 4, 6, 3 is the layer # of res34
  ulevel: 3
  ylevels: [3, 3, 3]

  # margin when calculating triplet loss
  margin: 0.3

  # use torch checkpoint to save memory on training
  memory_trade: True

# coefficients when calculating multi-task loss
coefficients:
  task_tm: 0.5 * x ** 4
  task_seg: 1 - 0.2 * (x ** 0.5)

datasets:
  - set2
  - set3
  - BUSI

# trainer flag
flag:
  gpus: [3]
  min_epochs: 40
  max_epochs: 80
  num_sanity_val_steps: 0
  log_every_n_steps: 10
  terminate_on_nan: True

misc:
  augment: 1200
  continue: False
  load_from: latest
  use_annotation_from: 0

optimizer:
  - AdamW
  - lr: 4e-3

# LRReduceOnPlateau only
scheduler: null

# branch is used to control behaviors of diverse param groups.
# args here will override those in optimizer and scheduler
branch:
  M:
    scheduler:
      factor: 0.9
      patience: 4

dataloader:
  training:
    # batchsize_k is the image num per class in a batch
    batchsize_k: 10
    distrib_title: Ym
    shuffle: True

  # for evaluating, validating, testing
  validating:
    batch_size: 16

paths:
  name: ynet
  model_dir: model/toynetv1/ynet
  log_dir: log/toynetv1/{date}
  post_training: src/post_training.py
